---
title: 'Holistic Causal Learning with Causal Graphs: A Credible Method for Study Design and Preregistration in the Social Sciences'
date: today
date-format: long
author:
  - name: Robert Kubinec
    corresponding: true
    email: rkubinec@mailbox.sc.edu
    affiliations:
      - ref: nyuad
filters:
 - authors-block
affiliations:
  - id: nyuad
    name: University of South Carolina
    city: Columbia
    state: South Carolina
    country: United States of America
abstract: "While research designs in the social sciences have employed increasingly sophisticated methods to control false positive rates, there is still substantial debate about the merit of pre-registration and other recent open science reforms. In this paper, I present a method for preregistering causal graphs and employing the metric of entropy, and in particular Jaynes' theory of maximum entropy, to propose a holistic way of measuring the contribution of a research study. To demonstrate the method's utility, I show how recent research in both COVID-19 and political authoritarianism can be fruitfully understood using causal graphs and entropy. Additionally, I provide R code to enable researchers to compute these metrics, helping them prepare for various outcomes and learning approaches for the purpose of preregistration.^[A reproducible version of this paper with code is available at https://github.com/saudiwin/causality/blob/master/prereg_causal_graph.qmd . I thank David Waldner, Christopher Winship, Michael Poznansky, Kevin Munger, Arthur Spirling, Andrew Gelman, Kosuke Imai and participants in Polmeth Asia 2023 for helpful comments on this manuscript.]"
bibliography: references.bib
toc: false
fontsize: 12pt
linestretch: 1.7
fontfamily: times
format: 
  pdf:
    documentclass: article
    keep-tex: true
    includes-in-header: 
      - file: preamble2.tex
    geometry:
      - margin=1in
---

<!-- -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning=FALSE,
                      message = FALSE,
                      fig.align = 'center')

#^[Title is a reference to a tweet by the eminent statistician Noah Haber https://twitter.com/NoahHaber/status/1584555245069545473.]

# to install quickDAG, use *this* command to get correct version:
set.seed(74662)

require(dplyr)
library(tidyr)
require(ggplot2)
require(ggthemes)
require(quickdag)
require(entropy)
require(network)
require(ggnetwork)
require(dagitty)
require(DiagrammeR)
require(rmutil)
require(jmuOutlier)
library(CausalQueries)
```

\newpage

<!-- The renewed attention to causal identification in the last twenty years has elevated the status of the randomized experiment to the sine qua non gold standard of the social sciences. Nonetheless, research employing observational data, both qualitative and quantitative, continues unabated, albeit with a new wrinkle: because observational data cannot, by definition, assign cases to receive causal treatments, any conclusions from these studies must be descriptive, rather than causal. However, even though this new norm has received widespread adoption in the social sciences, the way that social scientists discuss and interpret their data often departs from this clean-cut approach. Analyses with observational data continue to be performed in a way that suggests causal interpretations, and even qualitative evidence is cited as valid explanation for human actions. This disjuncture between the clean logic of counterfactual causal inference and actual practice has created considerable confusion among researchers who must decide whether to devote precious resources to observational data collection that is fatally doomed regardless of its promise or a (quasi-)experiment even if that experiment would not answer their research question. -->

<!--# This paper inverts the meaning of gold standard with respect to causality by considering the origin of the phrase in heated monetary debates of the 19th century. The quotation above by William Jennings Bryan referenced devaluation occurring in the United States as a consequence of pegging the dollar to gold reserves. When the price of gold increased, the money supply constricted and borrowers would have to pay more than they initially agreed to. Bryan and his confederates wanted to switch to the silver standard, of which there was a much more plentiful supply, in order to maximize much-needed specie for the United States' quickly growing economy.   -->

<!-- While the causal inference revolution has opened up vast new areas for empirical research, it has also faced criticism for pressuring researchers to produce causally-identified findings even when their data do not permit such conclusions. The underlying problem, I argue, is that scholars employ causal thinking in binary terms of the effect of single variables while ignoring larger questions about causal systems. Re-conceptualizing causality as containing distinct bivariate and multivariate forms can shift the conversation away from causal versus descriptive labels and towards some secret, other thing: the relative contribution of a study in terms of its reduction (or possibly inflation) of the entropy of a causal *system*. -->

<!-- The difficulty in relying solely on potential outcomes and randomization for causal inference is not that experiments can have serious flaws, although they do, but rather that scientists have yet to come up with a single empirically verifiable definition of causal relations. Causality is a latent concept; we can define with reference to examples, but the word's connotations are difficult to capture simply and clearly. Part of the problem is that causality does not refer to an observable physical process but rather to an existential frame within which human beings determine the processes that are and are not meaningful. For this reason, the social sciences are struggling not only with the estimation of uncertainty in methods, research design and the amount of data, but with knowing what it is exactly that we aim to accomplish with all this endeavor. As a result, if we assume that the beneficial properties of certain statistical paradigms make them the definition of causality, we commit a subtle logical fallacy. -->

<!-- To do so, I will claim in this paper that *causal identification* is not necessary for learning about causal systems. This statement is not to disparage existing theorems about identification, nor to challenge the utility of the literature for research. Rather, causal identification is a sufficient condition for causal learning about systems, but it is not necessary because we can obtain information about joint distributions of variables even when each variable singly is possibly confounded. -->

The past decade has seen remarkable changes in how social scientists are expected to conduct research studies, especially when the study involves experiments or aims for causal inference more generally. In order to combat questionable research practices (QRPs) that undermine statistical findings [@schneiderSomethingRottenState2023], open science reformers have proposed pre-registration as a form of binding commitment device that (in theory) forces researchers to report all relevant analyses [@scogginsMeasuringTransparencySocial2023]. Indeed, some political science journals have recently made pre-registration mandatory,[^1] leading to an increasing adoption of the norm that pre-registration is necessary for experimental inference and possibly observational (or quasi-experimental) inference as well.

[^1]: For more information, see <https://tompepinsky.com/2021/01/16/on-requiring-pre-registration/>.

Despite this widespread adoption, evidence of the effectiveness of pre-registration remains scant and has been questioned recently [@brodeurPreregistrationPreanalysisPlans2024]. In one notable recent episode, Open Science Foundation authors used results from outside their own pre-registered study of the effect of pre-registrations [@bak-colemanClaimsScientificRigour2024], which the journal asked them to retract [@protzkoRetractionNoteHigh2024]. The basic logic of pre-registration as a "bind the hands" device has been further questioned as it may only shift the selection away from null effects and other undesirable research outcomes to a different stage [@schakenbergPreregistrationStrategicPrivate2024]. For these reasons, while pre-registration is becoming a growing norm, it is also increasingly under fire for failing to live up to its promises to make science a fairer, more transparent, and ultimately more credible enterprise.

In this paper, I propose a new method for understanding preregistration as involving a registration of the state of the world of researcher knowledge that is expressed in the form of a causal graph. This method builds on recent advances in social science research design that is increasing the capability of tools for applied researchers to diagnose issues and construct robust theories [@blair2023; @humphreys2023]. With a preregistered causal graph along with suitable priors over the relationships between variables [@humphreys2023], authors could then employ metrics based on entropy, in particular Jaynes' (2003) theory of maximum entropy, to determine the level of causal knowledge that a particular study would contribute. Importantly, knowing the amount of prior causal knowledge about a causal system would permit robust post hoc exploratory inference of the kind that is often done in the social sciences.

Based on Jaynes' theory, I provide a formal basis in this paper for two forms of causal learning: the more common type I causal learning (searching for new relationships) and the less common yet equally as important type II causal learning (learning from nulls as in @alrababah2022). Given an open-ended preregistration that allowed for both types of causal learning, study authors could then determine with much more precision the level of causal knowledge obtained *without requiring a specific set of analysis steps in the document*.

I propose that we can accomplish this objective by applying Jaynes' (2003) theory of maximum entropy to the evaluation of causal systems---specifically, by calculating the entropy of the joint distribution of variables in a causal graph. Entropy is a framework widely used in statistics to represent the relative amount of information present in a random variable [@shannon1948]. Entropy is a characteristic of a random variable's distribution; the flatter (more uncertain) the distribution, the more entropy exists. When applied to causal graphs [@pearl2000], the theory of maximum entropy requires us to begin with minimal assumptions and always seek to maximize our uncertainty given these set of minimal assumptions.

The aim of this method is to encourage researchers to make causal graphs central to their research by directly incorporating them into pre-study planning such as preregistrations. I further provide helpful guidelines for researchers to employ causal graphs in realistic settings where there is disagreement over the true causal process. I argue that even in cases where the definition of the causal system is uncertain, framing research designs in terms of causal graphs and employing Jaynes' theory of maximum entropy can provide helpful baselines for reasoning about optimal interventions for causal learning and avoid disagreements about the "correct" analyses to conduct following an experiment. For this reason, the method of entropy I propose is related to scholarship about obtaining real-world learning out of biased data distributions [@spirling2022; @huang2024; @dorie2016; @slough2023; @berinskyPublicationBiasesReplication2021].

I show how this framework can permit diverse forms of causal learning from case studies of two important cross-disciplinary research topics: the efficacy of COVID-19 vaccines and the relationship between a country's oil wealth and its level of democracy. I show through the case studies how observational, experimental, and mechanistic (qualitative) research designs can each contribute causal knowledge in varying amounts depending on the pre-specified causal structure. Given a fixed research budget, I even show how this method can even determine an optimal research design in terms of maximizing learning about causal systems given minimal assumptions.

The method of entropy developed in this study has applicability to the decision-making calculus involved in research design, the evaluation of the amount of learning from different studies, and the meta-analytic task of summarizing the amount learned from studies in a given field. The method can be estimated using R code provided in the appendix and makes use of new frameworks for power analysis and research design [@humphreys2023; @blair2023] to enable social scientists to be able to make valid and robust decisions about what kind of studies to pursue given constraints, as well as to defend their decisions to pursue a certain path of research even if they cannot guarantee the causal identification of relations between single variables in a given study.

# A Theory of the Learning of Causal Systems

<!-- The credibility revolution of the past fifteen (or so) years, which argues for the application of the potential outcomes framework and RCTs as a way of measuring the credibility of statistical analyses, has produced a sea change in how political scientists, economists and increasingly others measure research success. The potential outcome theories behind the credibility revolution date back to the 1970s or even earlier [@fisher1935; @rubin1974; @holland1986], but for whatever reason, the practice of formal randomized experiments did not take off in fields besides psychology until the 2000s [@green2003; @morgan2007; @levitt2008]. -->

<!-- More recently, a second credibility revolution has swept through social scientific disciplines that long employed experiments, particularly psychology. This second revolution has questioned the use of discretized decision rules, i.e. p-values, as a source of inferring causal inference, and shown that many published experiments fail to replicate even if the original experiment had statistically significant results [@opensciencecollaboration2015; @gelman2013]. This revolution has emphasized pre-registering research questions [@nosek2018], sharing data so that conclusions can be replicated or reproduced [@goodman2016], and even more radical changes, such as fundamentally altering the standards used to judge statistical inference [@benjamin2017; @amrhein2019]. While the first revolution has dramatically elevated the status of experimental research designs, the second has ironically pointed to deep problems in how RCTs have been implemented and evaluated. -->

<!-- As a result, there remain significant pockets of resentment at the success of the potential outcomes framework. The success of experiments appears to endanger the role of observational studies, whether qualitative or quantitative, as these studies can never meet the stringent criteria imposed by their randomized kin [@beck2006; @gerber2014; @gerstein2019]. To enforce the distinction, journals increasingly require scholars to avoid "causal" language like "impact" or "effect" when using observational methods [@hernán2018; @thapa2020; @yu2019]. -->

<!--# The most relevant paper to the causal-description binary, though, is the @gerring2012a definition of "mere" description as "aim[ing] to answer what questions … about a phenomenon or set of phenomena" (p. 722). By providing a definition for descriptive research, Gerring argued for thinking of description as an independent yet necessary task in the social and physical sciences. Gerring points out that the downstream consequence of failing to value descriptive research rests on research evaluation: "the fact remains that the descriptively oriented researcher faces a higher hurdle in the race to publication than the causally oriented researcher" (p. 741). In this paper, I take Gerring's ideas, one might say, to their logical conclusion: implementing research activities with the label "descriptive" can be of equal merit to causally-identified studies because these designs are different modes of causal learning. While descriptive types of research can be given an inductive definition, as Gerring does admirably well, it is still difficult to properly value "mere" description when it is considered ontologically separate from causal inference.  -->

<!-- Much of social science research starts with the straightforward research question of discerning the "effect" of $X$ on $Y$, such as the effect of rising incomes on preferences for democracy. This type of simplicity allows us to focus on particular research questions and related threats to inference, such as confounding variables that might account for a spurious observed association between $X$ and $Y$. In the last twenty years, work in the potential outcomes and causal graphs frameworks has highlighted just how difficult it is to posit that any conditional probability distribution of $P(Y|X)$ can be given a *causal* interpretation, where causality is defined either as the difference between the observed data and unobserved counterfactuals of $Y$ in which $X$ takes on different values [@rubin1974; @keele2015; @imbens2010; @green2003] or as employing the $do$ operator to "force" $X$ to take on certain values regardless of the distribution $Y$ (i.e., $P(Y|do(X)$) [@pearl2000]. -->

<!-- The intent of this paper is not to dispute these existing frameworks but rather to point out that the focus on single variable relations ($P(Y|X)$) does not address questions about more complex causal relations involving multiple variables, or what I term *causal systems*. I argue that the belief in some parts of the scientific community that contemporary causal inference methods are reductionist is in part an unintended consequence of these frameworks' focus on single variable relations. For example, it is much more difficult to discuss relations between three variables in potential outcomes or even some analyses of causal graphs, or what is often termed "mediation analysis." Attempting to coerce even a three-variable system into a purely experimental framework is tricky as it raises questions about how an experimental researcher could manipulate multiple variables simultaneously and how this maps on to theories of counterfactual potential outcomes [@tj2016; @imai2010] or in causal graph terms what one is exactly supposed to $do(\cdot)$. Thinking of potential outcomes or $do$ operators with four or more variables, especially when these vary over time and across units, raises even more difficult questions about how to understand causal inference, such as with the emerging literature on panel data [@callaway2020; @imai; @kropko2020]. -->

<!-- Even if research methods cannot provide straightforward means of causal identification, I will show in this paper that they can still provide causal learning because they help us understand causal systems that involve multiple variables. In addition to the counterfactual or manipulationist frameworks mentioned previously, we can also think of correlational/observational [@abadie2005; @campbell2016], and mechanistic/qualitative [@collier2010; @waldner2015] research as distinct modes of research. The lack of a clear differentiation between relations of single variables (the effect of $X$ on $Y$) and the relations of causal systems (how do $X$, $Y$ and $Z$ jointly influence each other) has led to unnecessary inflation or deflation of the value of individual research studies in terms of their level of causal identification. -->

<!--#As the reader likely is familiar with at least one of these modes of inference, and possibly all of them, I do not further define these here but instead include a more thorough explanation of each inference mode in section 1 of the supplementary information. The reader can also learn how these modes are defined through the case studies following the definition of entropy. The introduction of these three modes of inference for causal knowledge is a simplification to permit the exposition of the theory of causal entropy and is not meant to be taken as an exhaustive typology.   -->

```{=html}
<!--# Quite often, the types of studies that cannot meet contemporary causal identification standards are given the label "descriptive" or "exploratory", even though scholars often find such studies to be of great importance for understanding the social world. When these studies have implicit causal claims, as they often do despite efforts to police the use of causal language [@hernán2018], scholars are often left confused as to how to properly value this type of exploratory yet seemingly causally relevant research. I argue that at least part of this cognitive dissonance arises from a lack of appreciation for the challenges in studying causal systems.

However, there is an important distinction to be made in this discussion. My re-analysis of research design does not cover issues related to measurement validity [@cronbach1955], such as those in the @gerring2012 theory of "mere description." This type of threat to validity arises when we have multiple potential indicators for a latent concept and we must either decide on one or find a way to combine them. This type of measurement choice can have profound consequences on inference, such as the ongoing dispute about whether democratic backsliding has or has not occurred [@weitzel; @little].

Rather, the type of research that can be unfairly valued for lacking causal identification is that which permits leverage on joint distributions of variables. What I argue is that in this type of research, the researcher is in fact interested in learning information about causal systems as opposed to solely the effect of a particular variable on another, and as such can still learn information even if only changing our understanding of a joint distribution of variables. Descriptive research in the Gerring sense, on the other hand, is applicable to the definition of a bivariate relationship between an indicator and a concept where the direction of causality is of secondary concern.   -->
```
<!--# On the other hand, once the research design involves bivariate comparisons—or a comparison of a case to itself over time—I argue that some type of causal learning is possible even if causal identification is impossible. This position is similar in spirit to the "partial" causal identification literature [@duarte2023] except that the proposed framework is an attempt to move away from dichotomization entirely. In this paper I conceptualize causal learning as a continuous process, not unlike theories of Bayesian learning with flawed research designs [@little2021].  -->

```{=html}
<!-- In order to provide a framework for understanding diverse ways of measuring causal learning, I employ theories of entropy [@jaynes2003] as a helpful starting place for thinking about the uncertainty of a causal graph. Causal graphs are useful because each graph fully encodes assumptions about a causal process, which allows us to then employ metrics like entropy to make statements about the total uncertainty of a causal system. In addition, I show how this flexible framework can extend beyond traditional causal graphs to encapsulate ideas in qualitative inference such as mechanisms and process-tracing.

Before I further define this framework, it is worth situating this contribution relative to the growing body of innovative writing on optimal research design. @humphreys2023 offer a compelling method for combining quantitative and qualitative inferences through Bayesian probabilistic reasoning and particularly through causal graphs. By quantifying information that is otherwise difficult to incorporate into formal models, the authors provide a method that rigorously propagates uncertainty. As I will show, the method of entropy that I develop here integrates seamlessly with the work of @humphreys2023, especially as their framework permits the propagation of uncertainty into entropy metrics and consequently inferences as well. I also move beyond their framework by showing how entropy can even incorporate modifications to the standard definition of causal graphs.

It is important to note as well that I am far from the first to try to make sense of the causality and description dichotomy. After analyzing a difficult inference problem relating to breast cancer research, @imai2008 argued that "\[n\]either \[experimental nor observational design\] is better; both are adapted as well as possible to the constraints of their subjects and research situation" (p. 493). More recently, @ashworth2021 argued that theorists and empirical scholars need to understand the overlap between their approaches to avoid belittling research questions that have theoretical significance yet lack strict causal identification (and vice versa).

Similarly, @spirling2022 show how to combine diverse sources of information into an inference-to-the-best-explanation (IBE) framework. This type of work is also very important for learning how to combine evidence from diverse sources of data, and my theory of causal entropy can apply to the results of IBE analyses as explanations can be understood as references to causal systems. In summary, what I propose here is designed to build on rather than replace the growing work on probabilistic and causal inference. --\>

<!-- The main problem, I maintain, underlying these disagreements is an acute problem for social scientists: while we all want to obtain causal knowledge, we do not in fact know exactly what causal knowledge is. Existing research shows that causal thinking is deeply connected to human thought processes [@sloman2015]. Causality involves assigning meaning to events, an endeavor that in fact is part of the definition of rational thought [@brashier2020; @koslowski1996]. Perhaps because it is so foundational to how we process the world, we also have trouble encompassing precisely what we mean when we say a relation is causal versus spurious [@spirling2022]. -->
```
<!--# The difficulties in defining causation are nothing new as causality has been a subject of intense philosophical debate for several centuries, if not millennia [@koslowski1996]. Rather, my point is that it is easy for scientists to ignore this source of uncertainty in discussions of causal inference, which leads to unrealistic standards for what a particular framework of causality can achieve. If instead we borrow from our own analysis of latent concepts, in which we can measure indicators but never the concept directly [@gerring2012, pp. 105-155], we can then conceptualize of causality as a latent scale with uncertainty over its "true" location. As such, it makes more sense for scholars to discuss research as being more or less causal, or communicating more or less causal knowledge, than granting some studies the "causally-identified" label while other studies are relegated to the merely exploratory.  -->

To make preregistrations optimally useful, they must be understood within a larger theory of inference. Existing frameworks for preregistration tend to follow a Popperian type of logic in which the scientist derives hypotheses independent of data collection [@popperScienceFalsification1963], and experiments are attempts to refute or confirm these previously derived hypotheses. While it is not my aim to dispute this common understanding of the scientific process--though it has notable critics [@agassiPopperHisPopular2022]--it is rather much easier to point out that in social scientific practice, the Popperian ideal is rarely if ever achieved [@caldwellProblemsFalsificationismEconomics1984]. Our theories are too imprecise [@frankenhuisStrategicAmbiguitySocial2022], our measures are too noisy [@flake2019], and our data collection is too difficult to allow for tests that can be seen as fully confirming or disconfirming for most studies we perform [@gelmanStatisticsCrisisReplication2015].

The traditional view of preregistration cited earlier has its aim of bringing science closer to the falsificationist goal. Similarly, the recent criticism of the movement alleges that preregistration norms have failed to stop p-hacking and other QRPs. However, preregistration can serve multiple aims, not all of which have to do with falsification per se. After all, much of social science research is exploratory [@swedbergExploratoryResearch2020; @gerring2012a], either because existing theories do not cover the empirical data, or because the theories are too imprecise as to provide clear predictions before observing the data. Given this difficulty, preregistration of causal graphs provides a path forward for permitting exploratory analyses that are robust and credible but also do not require researchers to invent post-hoc theoretical justifications for their decisions.

There is a vast and growing literature on causal graphs, much of it stemming from the @pearl2000 revival of interest in causal systems. While social-scientific research designs often assume a binary treatment and a binary outcome, social science theories can make use of many variables, and causal graphs are able to incorporate much more of this complexity than the potential outcomes framework can permit. This flexibility is very important for avoiding the previously described issues of preregistrations as $p$-hacking very often involves subgroup analyses and other exploratory approaches that incorporate additional variables.

This paper is certainly not the first to show that causal graphs can help advance research goals in difficult areas. These type of structural causal models have been increasingly applied to diverse phenomena across the social sciences [@blackwellFrameworkDynamicCausal2013; @liuPracticalGuideCounterfactual2024; @waldner2015]. My intention here is to incorporate causal graphs in the same manner as @humphreys2023 recent work in terms of a tool for organizing and understanding theories which are subsequently tested with data. I defer the reader to their treatment for a more thorough understanding of the underpinnings of causal graphs and their relationship to individual research designs.

One of the most important objections to relying on causal graphs is that it is difficult to know when a causal graph is correct, or in the parlance of the literature, complete [@waldner2015]. Theoretically, a complete causal graph would permit a scholar to determine causal relations from purely observational data; practically, if we knew true causal graphs for social processes, we would have little need of further research. A true causal graph is a multidimensional analogue of the frequentist idea of a population parameter: while we want to find this quantity, we can never know for certain what it is except in expectation.

Nevertheless, I argue that a causal graph can help even in situations where substantial uncertainty exists over the true causal graph, as I explain in this paper. So long as the analysis can limit itself to a specific set of variables—which is in many cases a requirement for any kind of research study—then a causal graph, even a very simple one, can be derived. Given the full range of potential causal graphs, even up to the set of all bidirectional graphs, the entropy metric can then be used to determine how much causal learning is possible depending on the type of research design that is pursued.

Entropy is a concept with a long history in statistics, though in this paper it is used primarily as a way of making nuanced statements about the sum total of uncertainty in a causal system. In general, entropy describes the decay of a system, such as gas molecules moving farther and farther apart to fill a sphere. Statistical, or Shannon, entropy applies the same concept to probability, providing a measure of the "information" in a random variable [@shannon1948].

<!-- In general, as a probability distribution becomes more equal or uniform, entropy increases because all outcomes are equally likely, whereas when a probability distribution becomes more degenerate or peaked, entropy decreases as some outcomes are more certain than others. -->

Shannon entropy $H$ is defined as a simple formula applied to a distribution of $N$ probabilities that cumulatively sum to 1:

```{=tex}
\begin{equation}
\label{shannon}
H = - \sum_{n=1}^N p_n \text{log}p_n
\end{equation}
```
<!-- , but its appeal is in meeting certain qualifications for determining an entropy measure of probability, including that it increases as it moves away from neutral probabilities over outcomes (such as $\frac{1}{N}$) and reaches a minimum at 0 when any of the probabilities are equal to 1 -->

The formula in (\ref{shannon}) is unfortunately not intuitive, in part because the units of entropy are in logarithms. Because I am interested in entropy as a framework rather than with a particular empirical application, I use the more intuitive logarithmic base of 1.01:

```{=tex}
\begin{equation}
\label{myv}
H = - \sum_{n=1}^N p_n \text{log}_{1.01}p_n
\end{equation}
```
A base of 1.01 means that every unit increase in entropy equals a one percent increase in entropy. Figure 3 plots entropy calculations for probability distributions with varying levels of uncertainty or spread-out-ness. What is important to note is that all of these distributions have the same expected, or average, value, but are nonetheless very different statements about underlying uncertainty. Roughly speaking, the uniform distribution has 100 percent more entropy than the normal distribution, which has 30 percent more entropy than the student's T and Laplace distributions. These plots show why entropy is a powerful heuristic: it captures our sense of how certain we are of the empirical possibilities underlying a distribution of probability that is independent of the form of the distribution. If we know nothing about a process, we can assume a uniform distribution that leaves probability mass on all possible outcomes, or what is known as the maximum entropy distribution per Jaynes. But if we know more about how a process operates, we can considerably reduce our uncertainty (and hence entropy) by choosing a more specified distribution.

It is worth noting that entropy and variance are both statements about the uncertainty in a statistical distribution but are not interchangeable. Changes in the variance of variables, such as through Bayesian updating, provide similar information to entropy when considering repeated observations of the same random variable [@humphreys2023, p. 327]. However, it is important to note that in general entropy is a completely different measure than variance. Entropy does not carry the units of a random variable as the variance does, which permits entropy to be used across variables of different distributions (or even unknown distributions) in the same causal system. Variance is also defined as the second moment of a given distribution, while entropy is not a moment of any kind. Conceptually, entropy combines information from different moments, including variance, skewness and kurtosis, which is the reason it is often the basis for general measures of model fit like the (Wanatabe-)Akaike information criterion (AIC).

Finally and most importantly, theories and lemmas built on entropy, such as Jaynes' maximum entropy considered here, do not hold when variance is the underlying measure. The relationship between variance and entropy varies significantly across distributions [@mukherjee1986], which limits the utility of relying on variance as a heuristic for entropy.

```{r dement, fig.cap="Entropy Calculations Based on Empirical Densities of Statistical Distributions"}
#| label: fig-dement

plot_d <- data_frame(Distribution=rep(c('Uniform',
                                        'Gaussian',
                                        "Student's T",
                                        "Laplace"),
                                      each=1000),
                     Variates=c(runif(1000,min=-10,max=10),
                                rnorm(1000,mean = 0,sd=2),
                                rt(1000,3),
                                rlaplace(1000)))
my_ent_func <- function(mydist) {
  counts <- discretize(mydist,100,r = c(-10,10))
  counts_p <- counts/sum(counts)
  # need to drop zeroes
  -sum(counts_p[counts_p>0]*log(counts_p[counts_p>0],1.01))
}
plot_text <- group_by(plot_d,Distribution) %>% 
  distinct %>% 
  mutate(Entropy=paste0('Entropy = ',round(my_ent_func(Variates),0))) %>% 
  select(Distribution, Entropy) %>% 
  distinct
# plot the density in a facet wrap
plot_d %>% 
  ggplot(aes(x=Variates)) +
  geom_density(alpha=0.5,fill='blue',colour=NA) +
  facet_wrap(~Distribution,ncol=2,
             scales='free_x') +
  geom_text(data=plot_text,aes(label=Entropy),x=0,
                            y=0.2,
            fontface='bold',
            size=3) +
  ylab('Density') +
  theme(panel.grid = element_blank(),
        panel.background = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(face='bold')) +
  labs(caption="Because these are continuous distributions and entropy is a measure\nof discrete random variables, the continuous variates were first binned and then converted to probabilities.")
```

While entropy has been applied successfully to many statistical problems, my intention in defining it here is to think of it as a way to understand the relative value of the different research designs, whether they be experimental or observational. The maximum entropy principle provides clarity about how we can maximize knowledge while avoiding overconfidence. @jaynes2003 defines the maximum entropy principle as always preferring a distribution of higher entropy conditional on including all known facts in the distribution. For example, suppose we wanted to predict stock market prices. Lacking any special knowledge of stock prices, we would want our uncertainty to reflect the fact that all we have to analyze are the movements of individual stocks over time--we would want to maximize entropy or uncertainty, given the data we have. But if we knew that the Federal Reserve intended to increase interest rates, we could include that information in our model and consequently obtain a lower entropy distribution.

Ultimately, the goal of the social sciences should be to reduce entropy whenever possible in terms of our understanding of how the social world operates. If we have a more certain knowledge of the distribution of outcomes, we can state with reasonable confidence that our knowledge is increasing [@gerring2006]. To do so, we have to produce new propositions that explain human behavior and allow us to make judgments about what is more or less likely to occur. From a Bayesian point of view, we could re-state this problem as meaning that we should always prefer the research design that increases our knowledge relative to our prior, even if the knowledge we obtain has residual bias [@little2021].

In other words, we want to learn new facts about the world such that we reduce our entropy in understanding causal systems. At the same time, we want to maximize entropy given what we know to reduce blind spots and over-confidence. Causal inference involves striking this delicate balance between assuming too much and assuming too little [@clarke2007].

Based on the principle of maximum entropy, I consider two ways that changes in entropy can map onto learning about causal systems. Generally, we tend to think of causal learning as involving reducing entropy, that is, reducing our uncertainty and adding structure to our understanding of the world. I call this *type I* causal learning. At the same time, if we are overconfident in our causal knowledge, we may need to instead inflate our uncertainty, or what I term *type II* causal learning. Type II causal learning relates to the growing body of literature about the importance of making inferences concerning "null effects" in experiments [@alrababah2022].

<!-- This framework helps resolve some inconsistencies in how models are incorporated in the social sciences. On the one hand, more complex models are seen as embodying increased knowledge [@clarke2007; @slough2019]. On the other hand, there has been considerable push back at models that appear to be baroque and less easy to explain than tried-and-true ordinary least squares (OLS) regression [@angrist2008]. Maximum entropy helps explain these mixed feelings: we should prefer more complex models over simple models because our over-arching aim should be to reduce entropy, and more complex models have less entropy. On the other hand, we do not want to reduce entropy without a good reason lest we over-state our certainty [@frank2009]. -->

To use entropy to understand causal systems, I employ Pearl's directed a-cyclic graphs. My intention is not to suggest that Pearl's theory is the final take on causality, but rather that causal diagrams are flexible ways of encoding a wide array of assumptions about causality. As such, they are a helpful starting block for comparing very different representations of causality. There are existing applications of entropy to causal graphs, but the aim in the literature is to uncover hidden confounders given a set of observed data as opposed to making larger statements about research design [@kocaoglu2020; @tee2016; @wieczorek2019].

It is important to note, however, that by employing causal graphs I am making the implicit statement that at least some assumptions are necessary for causal inference. This approach contrasts with the so-called "barefoot" experimentalist approach in which experiments can be applied iteratively to learn causal relations without the need for theory or consideration for the larger causal system [@green2003; @deaton2018; @ashworth2021]. My employment of causal graphs is not intended to be a statement about this debate as my framework cannot be fruitfully applied without some structure to describe a causal system.

For these reasons, it is important to note that the minimal causal *system* is a causal graph of at least two nodes. A bivariate graph with only a single independent variable and single dependent variable is a perfectly acceptable starting place (and all the calculations in this paper apply) although the true power of causal graphs generally comes from understanding more complex systems. However, care must be taken when determining the set of nodes over which the causal system is to be defined. As is well-known, the complexity of a directed graph increases at a highly non-linear rate as each additional node $n \in \{1,2, ... N\}$ allows for $N+1(N) - N(N-1) = 2N$ additional edges (connections) between nodes. At the same time, taking into account the principle of maximum entropy, we would only want to exclude edges from a causal graph if such an assumption is uncontroversial. If there is residual uncertainty, we should include an edge between nodes in the graph. Thus the definition of a causal system involves the selection of a set of nodes, and research on the causal graph primarily focuses on adjudicating the types of edges (connections) between said nodes.

<!-- Let us imagine that we launched ourselves in a spaceship and landed in a foreign world. We have almost no prior knowledge of how people on this planet relate to each other, but we want to understand how the world's residents select their leaders. All we can do is come up with a list of plausible factors that might affect leader selection. Given our experience of such occurrences on earth, we come up with the following list of variables: political ideology (I), economic benefits (E), ethnic affinity (A), leader personal qualities (Q), and the risk of conflict (C). We can think of these variables as nodes in a network all connected with the outcome of leader selection (Y) as is shown in Figure 4. -->

<!-- ```{r netgraph, fig.cap="Causal Diagram with Complete Uncertainty"} -->

<!-- mat <- matrix(rep(1,36),6,6) -->

<!-- row.names(mat) <- c('I', -->

<!--                     'E', -->

<!--                     'A', -->

<!--                     'Q', -->

<!--                     'C', -->

<!--                     'Y') -->

<!-- colnames(mat) <- c('I', -->

<!--                     'E', -->

<!--                     'A', -->

<!--                     'Q', -->

<!--                     'C', -->

<!--                     'Y') -->

<!-- diag(mat) <- 0 -->

<!-- mat_edge <- matrix(rep('frac(1,36)',36),6,6) -->

<!-- netobj <- network(mat,directed=T) -->

<!-- set.edge.value(netobj,'Probability',mat_edge) -->

<!-- ggplot(netobj, aes(x = x, y = y, xend = xend, yend = yend)) + -->

<!--   geom_edges(color = "grey50", -->

<!--              arrow=arrow(length = unit(0.5, "lines"), type = "closed")) + -->

<!--   geom_nodetext(aes(label=vertex.names), -->

<!--                 size=7) + -->

<!--   geom_edgetext_repel(aes(label=Probability),parse = T, -->

<!--                       label.size=NA) + -->

<!--   theme_blank() -->

<!-- ``` -->

<!-- Each edge in this graph is labeled with the dual expected probabilities that a link exists in either direction, with each one labeled $\frac{1}{36}$ to represent our current ignorance, i.e., any link between any of the nodes is equally likely in either causal direction. The edges in this network are bi-directional to show that our in our state of complete uncertainty we cannot even say what the direction of causality could be. While the uncertainty in this figure is extreme, it comes closer to the actual state of social science research than the elegant causal graphs in many texts derived from mechanical examples. -->

<!-- Given the previous discussion, the question now is to reason about which method of causal inference to apply to Figure @ref(fig:netgraph). The easiest way to answer this question, and one often chosen, is simply to choose whichever method best fits the researcher's skills and experiences. While very practical, it poses a chicken-and-egg problem, and only shifts the question to which paradigm researchers should invest in to gain experience and skills. -->

<!-- I propose that a better heuristic is to ask what would reduce entropy in the causal graph. There are very complicated entropy statistics for graphs, but to simplify matters I apply the entropy formula to each edge probability in Figure @ref(fig:netgraph): -->

<!-- $$ -->

<!-- -\sum_1^{36} \frac{1}{36} \text{log}_{1.01} \frac{1}{36} = 360 -->

<!-- $$ -->

<!-- We start with the considerably high number of 360. At this amount of entropy, we are not likely to be wrong, but we also cannot say much of value about our study of this foreign planet's society. Initially, let us consider a choice between an experimental and an observational analysis. Suppose than with an experiment we can determine directly the probability of the connection between ethnic affinity (A) and leader selection (Y).[^2] If we pull off a quality experiment, we can double the probability of the link from $A \rightarrow Y$ and reduce the probability of the link from $Y \rightarrow A$ (reverse causality) to 0. We can consider the experiment to be *causally identified* because it is possible, given enough experimental data, to either rule out or establish the relationship between these two nodes [@keele2015]. Then we can re-calculate our entropy measure, which shows a decrease in entropy of 4 percent: -->

<!-- [^2]: We ignore for the time being the difficulty in enacting these research designs. -->

<!-- $$ -->

<!-- -[(\sum_{1}^{34} \frac{1}{36} \text{log}_{1.01} \frac{1}{36}) + \frac{2}{36}\text{log}_{1.01}\frac{2}{36}] = 356 -->

<!-- $$ -->

<!-- However, suppose that if we conducted an observational data analysis, we could increase or decrease the probability of the links between leader selection and economic benefits (E), leadership quality (Q), ideology (I), ethnic affinity (A) and conflict (C) from $\frac{1}{36}$ to $\frac{1.5}{36}$ while lowering the opposite links to $\frac{0.5}{36}$. This research design is not causally identified because we cannot be sure, i.e. we cannot know with probabilities approaching one, what effect any one of these variables have on the outcome, *only their joint distribution*. This analysis would result in the following change in entropy: -->

<!-- $$ -->

<!-- -[\sum_{1}^{26} \frac{1}{36} \text{log}_{1.01} \frac{1}{36} + \sum_{1}^{5} \frac{1.5}{36}\text{log}_{1.01}\frac{1.5}{36} + \sum_{1}^{5} \frac{0.5}{36}\text{log}_{1.01}\frac{0.5}{36}] = 356 -->

<!-- $$ -->

<!-- In other words, in this example, the observational and experimental studies would have similar effects on reducing the entropy of the total system *even though they made very different statements about the underlying causal structure*. Intuitively, we can learn a lot from establishing a specific causal link in a specific direction with a high degree of certainty, but we can also learn a lot from examining associations between variables, even if we cannot arrive at conclusive predictions. The point of this exercise is not to suggest that observational methods are better than experimental methods, but rather that the value of each depends on the nature of the causal problem, and it is *not* always the case that experiments produce more causal knowledge than observational studies. -->

<!-- We can further extend this discussion by considering the mechanisms implied by the edges. Instead of treating the edges as solely representing causal relationships, we could imagine a distribution over mechanisms for each edge. We could similarly decrease our entropy over mechanisms by learning which mechanisms are the most likely and least likely for a given node. Uncertainty over mechanisms could then be weighted with the overall association probability as entropy is additive on the log scale. -->

Once the analyst has chosen the set of variables which pertain to the research question, it is possible to calculate entropy of any number of possible causal graphs. I now formally define the causal entropy measure as the Shannon entropy $H(\cdot)$ of an ordered set of variables (nodes) $\{x_1, ... x_N\}$ that can be represented by a causal graph $v$ which meets all of Pearl's requirements: it includes a set of directed edges $e \in E$ between each variables $x_i$ in the graph and is acyclic. Because the graph is ordered, there is necessarily at least one terminal node that represents the outcome that the graph seeks to explain. We can then take the Shannon entropy $H(\cdot)$ of the joint distribution of these variables (indexed by $i \in N$) with respect to a given terminal node or outcome, which can be denoted $P(v)$, following Pearl's notation:

```{=tex}
\begin{equation}
\label{entgraph}
H(P(v)) = - \sum_{i=1}^N P(x_i | pa_i) P(pa_i) \text{log}P(x_i | pa_i) P(pa_i)
\end{equation}
```
Where the notation $P(x_i | pa_i)$ indicates that each component of $P(v)$ is the conditional distribution of each variable $x_i$ in $V$ with respect to the set of its ancestors $pa_i$ that are causally relevant to $x_i$. Due to the Markov property of causal graphs [@pearl2000, Ch. 1], we only need to consider the immediate set of ancestors as causally relevant, which significantly simplifies the construction of conditional probabilities for a given $x_i$. Because $P(v)$ is a joint distribution over all such relations, it meets the requirement that the probabilities of all of the causal relations sum to 1.

Formally, we can then consider research designs as representing different joint distributions, such as $P(v)$ and $P(v')$. We can state that a research design that results in $P(v)$ creates more type I causal knowledge than a research design that produces $P(v')$ iff:

```{=tex}
\begin{equation}
\label{greaterent}
H(P(v)) < H(P(v'))
\end{equation}
```
Conversely, to understand type II causal learning, we need a measure of cross-entropy, or comparing the entropy of two distributions. We can suppose first that we have a maximum causal entropy distribution $P(q)$ for a given causal graph which represents a state of maximum uncertainty about the causal process. We also suppose that the current state of the research field accepts a reduced causal entropy distribution $P(v) | H(P(v)) < H(P(q))$, but this distribution is based on flawed data or assumptions, resulting in overconfidence.

We could obtain type II causal learning if we were to implement a replication study $P(v')$ that results in higher entropy than $P(v)$, bringing us closer to the maximum entropy of $P(q)$. With the maximum entropy distribution $P(q)$ as our baseline, the amount of type II causal learning we obtain depends on how much the Kullback-Leibler divergence $D_{KL}(P(q) \mathrel{\Vert} P(v))$ decreases from the maximum entropy distribution following the replication $P(v')$:

```{=tex}
\begin{equation}
\label{kldiverge}
H(P(q)) + D_{KL}(P(q) \mathrel{\Vert} P(v)) > H(P(q)) + D_{KL}(P(q) \mathrel{\Vert} P(v'))
\end{equation}
```
In other words, if our replication exercise $P(v')$ raises our uncertainty about the causal graph $P(v)$ relative to the limiting case of the maximum entropy distribution $P(q)$, then we can say that we have obtained type II causal knowledge in that we are no longer overconfident about the causal process. This notation shows how we could quantify such an increase in knowledge; it does not specify under what standards we would believe $P(v')$ to be more credible than $P(v)$. As mentioned previously, entropy is about understanding the relative level of type I or type II causal learning from a given inference but is not a criterion for deciding which inferences are based on credible information. What we gain from this framework is primarily a way of comparing different causal graphs with the same number of nodes yet varying types of edges between nodes.

Estimating type II learning requires a maximum entropy distribution as a the baseline, but these are relatively easy to derive for most cases. As was shown in @fig-dement, the uniform distribution is the maximum entropy distribution if there is no other structure or information to be taken into account. In the case studies that follow, I will use the uniform distribution as the maximum entropy distribution, or what I will refer to as the "null" graph. The Normal or Gaussian distribution is the maximum entropy distribution for any continuous variable with finite variance [@jaynes2003], and so it can serve as a null graph in the case in which units are not discrete probabilities.

One complication is that entropy is only defined over discrete variables. However, it is straightforward to calculate the entropy of a continuous variable through a binning procedure, and the measure is available via a wide array of statistical software packages [@hausser2021]. In the appendix, I provide a tutorial with R code showing how to calculate these quantities given different causal graphs. I further show in the appendix how the framework of @humphreys2023 can model causal systems in which there is uncertainty in the probability of edges between nodes via the Dirichlet distribution; this methodology permits statistical inference on changes in type I and type II causal learning for different research designs, though it also requires the specification of prior distributions over nodes in the causal graph.

Once we have defined these forms of learning about causal systems, we can further define an optimal research design $q^*$ as that which maximizes a research utility function for entropy minimization (type I causal learning) given a prior graph $P(v)$, a set of plausible research designs $Q = \{P(v_1),P(v_2), P(v_3) ... P(v_N)\}$, and a mapping of costs for each research design $C = \{c_1,c_2, c_3 ... c_N\}$ where we select the research design that maximizes type I learning given a budget constraint $B$:

```{=tex}
\begin{align}
q^* = \text{arg max}_{q \in Q} &U_i(B - c_q - (H(q) - H(P(v))))\\
\text{s.t. }&U_i(\cdot) > 0
\end{align}
```
## Preregistration of Entropy and Causal Graphs

To make this method useful, however, it is not necessary to solve for the optimal research design. It is only necessary to derive such a graph–or distribution of possible graphs–prior to undertaking a given study. Once the prior causal graph is known–ideally with probabilities over possible edges–then exploratory inference is permissible as false positive rates are known. If the causal graph is preregistered—even a causal graph with substantial uncertainty—then any post-study analyses of the study's data will be valid so long as they are shown relative to the preexisting information included in the preregistration.

To demonstrate this point, consider Gelman and Loken's analysis of the so-called "garden of forking paths" that motivated much of the movement for preregistration [@gelman2013] in which we are concerned about obtaining an accurate test statistic $T(y)$ for a given dataset $y$. Gelman and Loken's concern was that the quantity reported in many papers is in fact a function of the actual data obtained (i.e., statistics to report depended on the outcome of the experiment), that is, $T(y,\theta(y))$ where $\theta(y)$ is a function that determines which statistics to report. Gelman and Loken's point is that test statistics are invalid if they are a function of the data that an analyst actually obtains. Preregistration is supposed to remove this endogeneity by stipulating the set of tests chosen $\theta$ ahead of time: $T(y,\theta)$ so that it has no relationship to the data an analyst obtains.

Gelman and Loken's concern with this endogeneity in how statistics are reported is that it can artificially reduce uncertainty, or what he calls the "researchers' degrees of freedom problem" (p. 1). Essentially, if the test selection function $\theta(y)$ is optimized to find the most interesting finding–or even if it does not but still depends on the data obtained, then the test statistic is evaluated against the null hypothesis, that is, supposing that nothing is known a priori about $T(y)$. In this case, the reported p-value is based on a faulty understanding of the sample size given that there is information about the outcome $y$ in the choice of test statistic $T(y,\theta(y))$--that is, if the outcome had been different, this particular test statistic would not have been chosen, and thus the sampling distribution of the test statistic is invalid.

However, if we have preregistered the causal graph that we believe can generate $y$, denoted $P(v_y)$, following the notation above, then we can always back out a more informed baseline than the null hypothesis–we know the inputs to $\theta(y)$ because our selection of test statistics is aimed at minimizing entropy and maximizing a posteriori causal learning: $\theta(y) = \text{arg min} H(P(v_y))$. This informative baseline—the state of our knowledge about the causal process—permits exploration without reaching misleading conclusions. We no longer have to pretend that we selected our tests $T(y)$ with no attention paid to the data at hand.

For example, suppose a scholar does an experimental study of voting behavior using a vignette experiment. The outcome $y$ is the proportion voting in the election and $T(y,D)$ are the analyses that the scholar could report examining the relationship between the treatment $D$ and the outcome $y$. Suppose that the scholar recorded some preregistered analyses $\theta$ and reports these in the paper for $T(y|D, \theta)$. These test statistics are evaluated against the null hypothesis and are valid as they are independent of the observed data. However, the analyst found a surprising treatment interaction between gender, denoted $G$, and voting $y$, but this analysis was not preregistered: $T(y|D,G,\theta(y))$. Because the analyst did not know the relationship would be surprising until after observing the data, the decision to choose to report it based on the observed dataset could result in misleading inferences if the analyst acted as though this had been their plan all along.

However, if $G$ was in the causal graph—even if the preanalysis plan did not include a specific test for $G$--then the amount learned from the new analysis can be understood as the difference in entropy of the null (or pregistered) graph $H(P(v_{yt-1}))$ and the entropy of the causal graph following the experiment $H(P(v_{yt+1}))$. This quantity is valid regardless of the number or type of analyses that are reported in the article because it entails making a holistic comparison of causal graphs inclusive of all variables that contribute to $y$. The null hypothesis for any particular test statistic $T(y)$ could be adjusted based on the preexisting level of uncertainty or entropy so that truly surprising findings would reflect those that actually change the posterior distribution of entropy, which is by nature inclusive of all variables in the causal graph.

Preregistration of causal graphs is in fact a very feasible process because of our growing computational ability to depict and analyze graphs. I show practically how to do so with R code in the appendix for estimating uncertainty in entropy given a proposed sample size and research design with the method of @humphreys2023. This formula could also be used for retrospectively assessing the cost and benefits of reproducing particular studies. The payoff of thinking about the entropy of causal systems is to allow for these relatively precise statements about the utility of research designs so that we can maximize our a posteriori learning without losing robustness.

## Mechanisms and Causal Graphs

In this section I briefly consider an extension to the method that permits qualitative research to be included along with quantitative studies. By doing so, I show that the proposed method of entropy is flexible enough to permit modifications to the definition of causal graphs for non-quantitative research designs. To do so, we can consider a distribution of mechanisms in the causal graph $V$, which I denote as the set $\Omega$. Each directed relation $P(x_i | pa_i)$ would have a corresponding distribution over mechanisms $\Omega$, where $P(\Omega|x_i,pa_i)$ represents the joint distribution of all mechanisms for a given relation.

Specifying mechanisms in this way departs from some existing understanding of qualitative research like process-tracing as providing evidence over the existence of edges connecting variables in a causal graph [@humphreys2023; @mahoney2012]. Incorporating mechanisms as separate entities permits mechanisms to be fundamentally distinct from variables, which captures the idea that mechanisms are root processes that connect variables as opposed to variables themselves [@waldner2015] and for that reason may not be easily quantifiable [@collier2011]. While it is not the intent of this article to adjudicate between these competing theories of mechanisms, it is important to note that entropy is flexible enough to allow for such non-traditional understandings of causal graphs.

Because of causal graphs' Markovian property, we can simplify the expression of the joint probability of mechanisms to $P(\Omega|x_i)P(pa_i)$ because each variable in a causal graph is independent of other variables in the causal graph once we factor in its parents. In other words, we only need to consider the mechanisms of each node but not each preceding node. We can then consider the joint of both distributions:

```{=tex}
\begin{equation}
\label{entmech}
H(P(v, \Omega)) = -\sum_{i=1}^N P(x_i | pa_i) P(\Omega|x_i)P(pa_i) \text{log}P(x_i | pa_i)P(\Omega|x_i)P(pa_i)
\end{equation}
```
If we consider a graph $V$ that had identical distributions for the probabilities of causal relations $P(v)$, but different distributions for mechanisms $P(\Omega')$, we could then define that a study that increased our type I understanding of mechanisms $P(\Omega')$ would be preferable iff:

```{=tex}
\begin{equation}
\label{greatermech}
H(P(v, \Omega)) > H(P(v, \Omega'))
\end{equation}
```
<!-- So far I have shown all results using Shannon entropy $H$. It is also possible to examine the Kullback-Leibler (KL) divergence [@kullback1951] between different probability distributions of $P(v)$. This measure of *relative* entropy is quite similar to Shannon entropy, so I do not address this further. Using the KL divergence could be useful in a situation where comparisons are made between multiple plausible causal graphs instead of comparing different research studies on the same causal graph as I do in this paper. -->

In summary, this application of entropy to causal graphs reveals how the concept of statistical entropy can shed light on the difficult decisions that must be made when considering research designs. As I explicate in the following case studies, it is straightforward to calculate the amount of type I causal learning from plausible interventions on causal graphs using these formulae. Ultimately, the criterion of entropy suggests that we aim for maximizing the amount we can learn, i.e. causal knowledge, from an application of any of the paradigms. Even weakly causally-identified designs can contribute causal knowledge, and so long as causal graphs are preregistered, can allow for robust exploratory inference that aims at maximizing causal learning and minimizing the costs of expensive data collection.

While I do not include further examples of type II causal learning, its delineation here is to show the flexibility of this method of comparing research designs, including those designed to test for the credibility of prior work. The many formulations of entropy, including Kullback-Leibler divergence [@kullback1951], allow us to subsume equally as many research designs that go beyond exploratory inference. For example, this framework could be combined with meta-analysis to allow for entropy-weighted contributions from different research designs.

<!-- Before proceeding, however, it is important to return to the maximum entropy criterion. In all of the case studies that I show, I assume that we do not become over-confident and reduce entropy further than we should, i.e., more than "natural" randomness. This type of outcome could occur if the evidence or data we obtain from a study is faulty in some way. As such, entropy is best used as a metric for evaluating different research designs assuming that the designs are implemented appropriately. Practically, this type of analysis would be most useful for either meta-analyses of research findings that compares different studies on one causal graph, as I do in the following case studies, or for pre-registering research designs to show what the potential causal learning would be before undertaking a study. It is possible to also consider integrating this criterion into power analyses when multiple research designs are plausible candidates. -->

## Case Study: COVID-19 Vaccines

In this case study, I show how even a relatively simple three-variable causal graph, along with relevant entropy calculations, can cover a range of possible studies, including experimental, observational, and qualitative analyses. Importantly, all of the information necessary to understand the amount of causal learning can be inferred directly from the causal graph (although this is a post-hoc analysis as the studies I discuss did not have this causal graph preregistered). The aim of the case study is to show this method can be practically applied to actual research problems. In the appendix, I consider an additional case with a more complicated causal graph involving the relationship between oil and authoritarianism in the Arabian peninsula.

The outbreak of the COVID-19 pandemic offers an important test case for understanding how researchers employed research designs to understand and prevent COVID-19 infections. Because of the speed of the outbreak and the enormous scale of research efforts, there was relatively little time for traditional disciplinary norms to determine research designs. The SARS-CoV-2 virus did not care for disciplinary preferences, forcing researchers to employ whatever methods they had available to study the pandemic. The extreme pressures of this exogenous shock is the reason why I choose this particular area of research even though it is not a part of the social sciences proper. Under pressure, scientists went with their causal intuitions as opposed to relying on traditional disciplinary hierarchies, producing innovative work that built across modes of inference rather than relying on one mode at the expense of others. In addition, the massive levels of funding available from governments overcame one of the most common non-methodological factors in determining research designs, permitting issues of inference to become relatively more important.

Although there are many possible research questions, in this case study I focus on one crucial area: the development of vaccines. At first blush, it would seem that vaccines are a relatively straightforward exercise in terms of research design. After months of development, the drug companies Pfizer-BioNTech and Moderna released studies describing massive RCTs employing hundreds of thousands of volunteers over months. These studies provided concise and clear numbers concerning *vaccine efficacy* or the ratio of infected individuals in the treatment group to the number infected in the control group [@polack2020; @baden2021]. Because the control group never received a vaccine, the difference between the two groups could be directly attributed to the drug.

```{r dag1,echo=FALSE,warning=FALSE,fig.cap='Directed Acyclic Causal Graph for Confounded Vaccine Uptake',message=FALSE}
#| label: fig-dag1
unctrl <- "T I Z"
ctrl <- "T"

# paths
meas <- "T -> I     
          Z -> T"
unmeas <- "Z -> I "

output <- makeDAG(dagname='example1',filetype='png',
        text.nodes=unctrl,
        solid.edges = meas,
        dashed.edges=unmeas,
        embed=T,width = 1100, height=600)

knitr::include_graphics('example1.png',dpi=300)
```

In causal terms, this RCT solved a difficult yet well-known problem in studying COVID-19 infections: those who voluntarily participate in a COVID-19 vaccination study could be either more or less likely to be infected compared to those who would not want to volunteer for a vaccine. To give just one example, younger individuals showed less interest in vaccines compared to older individuals and were also much less likely to become severely ill. On the other hand, younger people may have been more likely than older people to contract a COVID-19 infection because they had less fear of serious illness or death. As a result, any naive comparison of a group of volunteers and the general population could end up conflating age differences with vaccine uptake [@hodgson2021; @baack2021]. This causal identification problem is a straightforward example of confounding, as shown in @fig-dag1. Any variable which could explain both vaccine uptake and the incidence of COVID-19 would be a confounding variable, and without confidence that we can collect data on and measure all confounding variables, we may not be able to identify the direct relationship between the vaccination and efficacy.

As is well-known, the Pfizer-BioNTech and Moderna trials proved to be a paragon of RCT methods, showing remarkably strong effects of the vaccine on efficacy, above 90%. This type of causal analysis was about as rigorous as possible for determining the precise nature of this bivariate relationship. At this point in the narrative, it would seem that RCTs had proven themselves as the gold standard: we had established that the vaccines worked, and now we could move forward with ending the pandemic. Indeed, such sentiments were common when the vaccines were introduced, leading to a relaxation of restrictions in the summer of 2021 [@bauer2021; @tregoning2021].

Fairly quickly, however, it became evident that the RCTs themselves were not sufficient to answer all the questions about vaccine efficacy. There were two main problems: first, people wanted to know how the vaccine performed *in the population*, which required attention to the confounding variables that the RCT successfully ignored [@hungerford2021], i.e., the role of the vaccine in the broader causal system. Second, the arrival of vaccine variants forced a re-evaluation of the vaccines' efficacy as RCT trials could not be run fast enough to keep up with new variants [@andrews2022]. These issues required both observational and mechanism-based modes of inference, as I will explicate below.

|                | I = Infected | I = Not Infected |
|----------------|--------------|------------------|
| T = Vaccine    | .15          | .85              |
| T = No Vaccine | .85          | .15              |

: $Pr(I|T,Z=\text{Old})$

To describe these studies in terms of learning about causal systems, we can calculate the entropy reductions of these different interventions on a causal graph. For simplicity, I will take as my starting point the causal graph in Figure @fig-dag1, where the nodes are labeled as $T$ for vaccine, one outcome, $I$ for infection, and a confounder $Z$ , which I will consider to be age. To simplify matters, I will treat each variable as having two discrete values.

To analyze the entropy of the causal process that produces $I$, we need to create the conditional probability distribution given the two nodes that both directly affect $I$. Tables 1, 2, and 3 show conditional probability distributions for the three variables with plausible values. To analyze the relationships in the causal graph, we need to consider two conditional probabilities, $Pr(I|V,Z)$ and $Pr(T|Z)$, and one unconditional probability, $Pr(Z)$. Because the first conditional probability involves two conditioning variables $V$ and $Z$, I separate this distribution of $I$ into two separate tables for Young and Old subjects as can be seen in Tables 1 and 2.

|                | I = Infected | I = Not Infected |
|----------------|--------------|------------------|
| T = Vaccine    | .02          | .98              |
| T = No Vaccine | .98          | .02              |

: $Pr(I|T,Z=\text{Young})$

|           | T = Vaccine | T = No Vaccine |
|-----------|-------------|----------------|
| Z = Young | .1          | .9             |
| Z = Old   | .9          | .1             |

: $Pr(T|Z)$

I assume here that these are the true probabilities of treatment efficacy and the confounding effect of age on vaccine uptake. It is important to note, too, that age also affects vaccine efficacy, with the vaccine more efficacious among the young than the old, as studies have shown [@bell2022]. To calculate entropy, we will need to start with a prior distribution representing what we think these relationships could be, or what I will call the null graph. For simplicity, I will assume a uniform prior for the null graph, i.e., that all of the probabilities in the tables are equal to exactly 0.5. While not shown, I can calculate the entropy by considering the full joint distribution of the causal graph, which involves creating a much larger table for all values of $Z$, $T$, and $I$, i.e. $P(I,Z,T) = P(I|T,Z) P(T|Z)P(Z)$. For reference, I also assume that the population is 25% young and 75% old for $P(Z)$.

```{r calc_ent_caus1}

prob_out_true <- tibble(pr_joint=c(.25*.02*.1,
                              .25*.98*.9,
                              .25*.98*.1,
                              .25*.02*.9,
                              .75*.15*.9,
                              .75*.85*.1,
                              .75*.85*.9,
                              .75*.15*.1),
                   I = c("I","I","H","H","I","I","H","H"),
                   `T` = c("T","C","T","C","T","C","T","C"),
                   Z = c("Young","Young","Young","Young","Old","Old","Old","Old"))

prob_out_prior <- tibble(pr_joint=rep(1/8,8),
                   I = c("I","I","H","H","I","I","H","H"),
                   `T` = c("T","C","T","C","T","C","T","C"),
                   Z = c("Young","Young","Young","Young","Old","Old","Old","Old"))

T0 <- .98*.25 + .85*.75
T1 <- .02*.25 + .15*.75
                   
prob_out_treat <- tibble(pr_joint=c(.5*T0*.5,
                              .5*T1*.5,
                              .5*T0*.5,
                              .5*T1*.5,
                              .5*T1*.5,
                              .5*T0*.5,
                              .5*T0*.5,
                              .5*T1*.5),
                   I = c("I","I","H","H","I","I","H","H"),
                   `T` = c("T","C","T","C","T","C","T","C"),
                   Z = c("Young","Young","Young","Young","Old","Old","Old","Old"))

ent_orig <- -sum(prob_out_prior$pr_joint*log(prob_out_prior$pr_joint,1.01))
ent_true <- -sum(prob_out_true$pr_joint*log(prob_out_true$pr_joint,1.01))
ent_treat <- -sum(prob_out_treat$pr_joint*log(prob_out_treat$pr_joint,1.01))

prob_out_true_mech <- bind_rows(prob_out_true, prob_out_true, .id="Omega") %>% 
  mutate(pr_joint=pr_joint*rep(c(0.1,0.9),each=n()/2))

prob_out_mech_prior <- bind_rows(prob_out_prior, prob_out_prior, .id="Omega") %>% 
  mutate(pr_joint=pr_joint*rep(c(0.5,0.5),each=n()/2))

prob_out_true_no_mech <- bind_rows(prob_out_true, prob_out_true, .id="Omega") %>% 
  mutate(pr_joint=pr_joint*rep(c(0.5,0.5),each=n()/2))

prob_out_treat_no_mech <- bind_rows(prob_out_treat, prob_out_treat, .id="Omega") %>% 
  mutate(pr_joint=pr_joint*rep(c(0.5,0.5),each=n()/2))

prob_out_treat_mech <- bind_rows(prob_out_treat, prob_out_treat, .id="Omega") %>% 
  mutate(pr_joint=pr_joint*rep(c(0.1,0.9),each=n()/2))

ent_true_mech <- -sum(prob_out_true_mech$pr_joint*log(prob_out_true_mech$pr_joint,1.01))
ent_prior_mech <- -sum(prob_out_mech_prior$pr_joint*log(prob_out_mech_prior$pr_joint,1.01))
ent_true_no_mech <- -sum(prob_out_true_no_mech$pr_joint*log(prob_out_true_no_mech$pr_joint,1.01))
ent_treat_no_mech <- -sum(prob_out_treat_no_mech$pr_joint*log(prob_out_treat_no_mech$pr_joint,1.01))

ent_treat_mech <- -sum(prob_out_treat_mech$pr_joint*log(prob_out_treat_mech$pr_joint,1.01))

# now try with causal queries

cq_orig <- make_model("T -> Y; Z -> T; Z -> Y")
cq_true <- make_model("T -> Y; Z -> T; Z -> Y")

# Z1 = Old
# T1 = Treated
# Y1 = Infected

cq_true <- set_parameters(cq_true,
                          parameters=c(.25,.75),
                          node="Z",nodal_type=c("0","1")) %>% 
          set_parameters(parameters=c(.9*.1,.1*.1,.9*.9,.1*.9),
                         node="T",
                         nodal_type=c("00","10","01","11")) %>% 
  set_parameters(parameters=c(.02*.15*.98*.85, # 0000
                              .98*.15*.98*.85, # 1000
                              .02*.85*.98*.85, # 0100
                              .98*.85*.98*.85, # 1100
                              .02*.15*.02*.85, # 0010
                              .98*.15*.02*.85, # 1010
                              .02*.85*.02*.85, # 0110
                              .98*.85*.02*.85, # 1110
                              .02*.15*.98*.15, # 0001
                              .98*.15*.98*.15, # 1001
                              .02*.85*.98*.15, # 0101
                              .98*.85*.98*.15, # 1101
                              .02*.15*.02*.15, # 0011
                              .98*.15*.02*.15, # 1011
                              .02*.85*.02*.15, # 0111
                              .98*.85*.02*.15), # 1111
                 node="Y",
                 nodal_type=c("0000","1000",
                              "0100","1100",
                              "0010","1010",
                              "0110","1110",
                              "0001","1001",
                              "0101","1101",
                              "0011","1011",
                              "0111","1111"))

# update default prior with the experiment (Y[X==1] - Y[X==0] = T1 - T0)
# treatment effect of -76.5% vaccine incidence

cq_treat <- set_parameters(cq_true,
                          parameters=c(.5,.5),
                          node="Z",nodal_type=c("0","1")) %>% 
          set_parameters(parameters=c(.25,.25,.25,.25),
                         node="T",
                         nodal_type=c("00","10","01","11")) %>% 
  set_parameters(parameters=c(.1175*.1175*.8825*.8825, # 0000
                              .8825*.1175*.8825*.8825, # 1000
                              .1175*.8825*.8825*.8825, # 0100
                              .8825*.8825*.8825*.8825, # 1100
                              .1175*.1175*.1175*.8825, # 0010
                              .8825*.1175*.1175*.8825, # 1010
                              .1175*.8825*.1175*.8825, # 0110
                              .8825*.8825*.1175*.8825, # 1110
                              .1175*.1175*.8825*.1175, # 0001
                              .8825*.1175*.8825*.1175, # 1001
                              .1175*.8825*.8825*.1175, # 0101
                              .8825*.8825*.8825*.1175, # 1101
                              .1175*.1175*.1175*.1175, # 0011
                              .8825*.1175*.1175*.1175, # 1011
                              .1175*.8825*.1175*.1175, # 0111
                              .8825*.8825*.1175*.11755), # 1111
                 node="Y",
                 nodal_type=c("0000","1000",
                              "0100","1100",
                              "0010","1010",
                              "0110","1110",
                              "0001","1001",
                              "0101","1101",
                              "0011","1011",
                              "0111","1111"))

q1 <- query_model(cq_treat, queries = "Y[T=0] - Y[T=1]")

# q1$mean should be identical to T0 - T1
        

get_entropy <- function(model, parameters = NULL) {
  p <- get_event_prob(model, parameters)
  -sum(p*log(p,base = 1.01))
}

# note that mechanisms don't exist, we would have to add these to 
# the framework, relatively easy to do though

# adding in priors would allow us to be a bit more specific

```

Calculation of Shannon entropy[^2] indicates that the null prior graph has an entropy of `r round(ent_orig, 0)`, while the true graph has an entropy of `r round(ent_true, 0)`. These two figures give us the relative space within which we can plausibly learn about this outcome. If we end up with an entropy of less than `r round(ent_true, 0)`, we will be over-confident, inferring causality to what are in fact random events. Respecting the lower bound reflects the principle of maximum entropy discussed earlier: we should not want to be more certain of conclusions than the underlying causal process permits.

[^2]: R code showing how to reproduce all calculations in this case study will be included with the article upon publication.

In this case study and the one that follows, though, I will focus on type I causal learning. We can directly calculate the reduction in entropy for the experimental analysis of the vaccine by inserting values of the conditional probability distributions from the true graph for $P(I|T,Z)$ into the null graph. By adding in the true values for the conditional distribution, not just the average treatment effect, I assume that the treatment was high-powered enough to inform us about the true joint distribution of both the treatment and the potential confounder, age, as seemed to be true for most of the vaccine trials with tens of thousands of subjects enrolled. The entropy of this high-powered experimental analysis is `r round(ent_treat,0)`, which is only 19% larger than the true entropy. As such, the experimental technique was clearly a powerful way of learning about this causal process.

```{=html}
<!-- First, consider the outcome of the massive number of experiments performed on elections, canvassing and voter behavior in American politics. @kalla2018 recently documented how 49 field experiments produced an average null effect of campaign advertisements and mailings on voter behavior. This finding is of course puzzling as campaigns spend a large amount of money to do what this study says is on average unlikely to occur: affect voter choices in an election.

This study is fascinating as it represents a field where the application of experiments has reached a far greater depth than other areas of political science. In this case, it would seem that we could reduce entropy to a greater degree in the study of voter behavior by looking at other methods than experiments, either observational large-N analysis or qualitative research aimed at identifying subsets of voters for interviews. Part of the problem, as the authors of the study note, is that there is widespread treatment heterogeneity, which is shorthand for a large number of background factors that also affect the success of the treatment. Observational and qualitative analysis could help uncover what these background factors are, such as broad geographical, economic or cultural factors, or very specific group or individual-level mechanisms that the treatment is interacting with. In other words, observational analysis could help situate the experimental findings within a broader theory as some have called for in psychology [@muthu2019].

Conversely, we can consider a situation where observational and qualitative analysis has been remarkably widespread: the study of democratization. @coppedge2012 documents the wide variety of statistical models fit to ever-increasing datasets, including most recently the Varieties of Democracy of Project [@vdem2017]. In addition, countless country-level case studies of democratic processes exist in the scholarly literature dating back to the origins of comparative political science [@Moore2003]. Yet there are relatively few if any experiments on building democratic institutions and on encouraging support for democracy as opposed to authoritarian politics, which suggests that entropy could be further reduced in this field by considering more experimental approaches. -->
```
However, the analysis left important information unanswered on the causal graph, in particular, what the relationship is between vaccine uptake and age. While the relative entropy would seem small, it is still an appreciable amount, and when vaccines were deployed to the population, it became a crucial factor for understanding the success of the vaccines [@hodgson2021]. If sicker people were more likely to take the vaccine, then the measures of vaccine efficacy from the total population would understate the efficacy of the vaccine. Understanding how the vaccine interacted with population demographics required obtaining data about vaccine uptake in the "real world" [@chodick2021], especially to combat misinformation about the efficacy of the vaccine by anti-vaccination groups. For this reason, it is clear that even though the most important question about the vaccine was answered by an RCT, there was ample room for observational studies that collected data on the spread of the vaccine and relative rates of COVID-19 incidence in the population.

Ultimately, these observational studies were necessary to uncover the remaining entropy in the causal graph, equivalent to a `r round(ent_treat,0) - round(ent_true,0)`% reduction in entropy. While this reduction was not as large as the reduction due to the experiment, it is important to note that this reduction could not be obtained from the experiment itself as it involved fixing the vaccine node $V$ to a particular value, such as with Pearl's $do$ operator. In this case, causal identification by fixing $T$ to a specific value in an RCT prevented any analysis of the $P(T|Z)$ relationship because by definition it removed that causal arrow from the graph. For this reason, an observational analysis that established the $P(T|Z)$ relationship---varying vaccine interest by age---would likely be labeled as descriptive, not causal. However, this distinction is relatively arbitrary when we consider learning about the causal system as a whole.

Finally, it is important to note that mechanistic analysis also played an important role in determining the efficacy of vaccines in the pandemic. As mentioned earlier, the success of the vaccines waned depending on the mutations of the virus, and it was infeasible to keep running large RCTs for each variant. This is a kind of threat to inference that is rarely discussed, and could be described as "temporal validity" [@munger2019]. To address this problem, scholars examined whether the same mechanism underlying the vaccine's efficacy also occurred in the same way with variants, namely, the production of virus-neutralizing antibodies. These studies were not necessarily statistical in nature, involving close examination of relatively small numbers of petri dishes with new SARS-CoV-2 variants in blood that had vaccine-induced antibodies [@yadav2021; @hoffmann2022]. Furthermore, these studies could not be directly integrated into the causal graph examined above because they refer to factors that are not present on the graph itself, i.e., minuscule changes in antibody levels.

We can expand the analysis to incorporate the antibody mechanism if we give it two values, High and Low. With these two values in the set $\Omega$, we can then calculate the entropy of the combined causal graph conditional on this mechanism for the relationship between vaccine $V$ and infections $I$:

```{=tex}
\begin{equation}
H(P(I,Z,T,\Omega)) = H(P(I|T,Z)P(\Omega|T)P(T|Z)Pr(Z))
\end{equation}
```
If we start with a null graph where the probability of $\Omega=\text{High}$ is 0.50, and the true value is 0.9, then we have null and true entropy values of `r round(ent_prior_mech,0)` and `r round(ent_true_mech,0)` respectively. If we performed the experiment successfully but without learning about mechanisms, we would obtain an entropy value of `r round(ent_treat_no_mech,0)` while an experiment that also involved learning about mechanisms would result in an entropy of `r round(ent_treat_mech,0)`, or `r round(ent_treat_no_mech,0) - round(ent_treat_mech,0)`% less. As can be seen, even with a single mechanism, relatively large reductions in entropy are possible by obtaining evidence of its true value. The reason for this large reduction is due to the fact that we know that the mechanism must be present for the causal story to hold about immunological response.

Of course, it could always be possible to look at antibodies as a mediator and expand the causal graph, allowing us to use mediation analysis to formally test for whether antibodies mediate the vaccine [@imai2010; @tj2016]. What is important, however, is that statistical tests were not necessary to make evidentiary statements about the presence or absence of the proposed mechanism. The proximity of observation and the logical necessity of antibody levels changing helped obtain causal inference about the performance of the vaccine against new variants even if there was no uncertainty interval or p-value attached. Statistical methods may not work well in this mode of inference because the attention to micro-processes often entails serious limitations in data collection in favor of richly textured information [@collier2010].

The point of this case study was not to argue that one mode of inference was superior to the other, but rather how each kind--experimental, observational, and mechanistic--played a valuable role in type I learning about a causal system that explained the level of infections at a given point in time. At different stages in the pandemic, each of these modes of inference helped determine the relative vaccine efficacy both against variants and in the population as a whole. While the RCT achieved the highest reduction in entropy of the causal system, other modes of inference had an important role to play. Once cost-benefit factors are included, such as the need to learn about efficacy against new variants for the purposes of booster shots, smaller overall changes in entropy can still be very important from a social welfare perspective.

In the appendix I include an additional case study examining research into the relationship between authoritarianism and the role of natural resources in rentier regimes. This case study employs a more sophisticated causal graph relative to the one previously described and likewise shows how different varieties of research designs, including experiments and process-tracing, can yield varying yet important amounts of learning about causal systems. With preregistration, these metrics could help make exploratory analyses of equal importance to more conventional falsificationist tests without privileging one or the other.

# Conclusion

<!-- I aver that many of our problems with defining and supporting descriptive research stems from our conception of causality as a binary process: either a piece of research is or is not causal. It is not that RCTs have more issues than are commonly acknowledged, but rather that the definition of RCT as the gold standard means that we artificially deflate the value of other modes of causal analysis. We should take a charitable approach by admitting that various theories and practices of inference contain varying amounts of causal knowledge, with the amount varying in relation to the credibility of the research design. However, as the maximum entropy principle shows, we cannot evaluate the relative causal knowledge obtained without a consideration of what is and is not known about a given causal system. -->

The principle of entropy provides one helpful framework by imagining the benefit of a study from the relative reduction or inflation in the entropy of a causal system. By doing so, we can change preregistration from a falsificationist standard to a more holistic and flexible form of preregistering our general state of knowledge of a causal process. This method can also be integrated into meta-analysis studies, especially if studies are explicit about the causal graph they seek to understand. Ultimately, the aim of the framework is to create a level playing field for diverse research designs—including both exploratory and confirmatory studies—so that we do not under-invest in important lines of inquiry that might yield important information about causal systems even if they fail to achieve causal identification of pairs of variables.

# Competing Interests

The author has no competing interests to declare.

# Data and Code Availability Statement

All data presented in this article is simulated from statistical distributions. All calculations shown in this article and referenced in the appendix are available from a public Github repository: <https://github.com/saudiwin/causality/>.

# Ethics and Inclusion Statement

This article solely makes use of data that is generated from simulated statistical distributions and as such there are no ethical issues to report in terms of human-derived data collection among marginalized populations.

\newpage

# References

::: {#refs}
:::
